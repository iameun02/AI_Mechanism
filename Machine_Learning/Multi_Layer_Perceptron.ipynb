{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uDvss2EuXx8-"
      },
      "source": [
        "# <b>Neural Network (신경망)</b>\n",
        " - 머신러닝분야에서 연구되는 함수형 알고리즘 (sklearn 라이브러리에 구현되어있음)\n",
        " - y = function(wx+b)\n",
        " - 학습대상 : w와 b\n",
        " - 학습목표 : True인 지역과 False인 지역을 나누는 분류 선 찾기\n",
        "\n",
        "<b> 퍼셉트론 (Perceptron = node = unit = function) </b>\n",
        "\n",
        "  - 여러가지 인공신경망 중의 하나면서 선형분리기\n",
        "  - 네트워크는 방향성을 가지고, 퍼셉트론은 기본적으로 Forward Network (왼쪽 → 오른쪽) 형태다.\n",
        "  - 퍼셉트론 하나를 직선의 형태로 표현 가능\n",
        "  - 동작원리 :\n",
        "    - 기본적으로 로지스틱과 동일 : 노드의 입력값(x)과 가중치(w)의 곱을 모두 합한후 \n",
        "    - 합한값이 활성화 함수(sigmoid)의 임계치(0.5) 이상은 1. 미만이면 0을 출력\n",
        "    - 하지만, logistic regression은 input layer →  output layer 로 연결되어 hidden layer가 없다 <br>\n",
        "      즉, 로지스틱회귀는 한개의 선으로 이진분류만 가능하지만, MLP는 여러개의 선으로 분류 가능하다.<br><br>\n",
        "\n",
        "  - 단일 퍼셉트론은 Logic Gate (진리표)대로 OR , AND, NAND(NOT AND) 게이트가 나오게 파라미터를 학습시키는데 성공시킴\n",
        "  - 하지만 XOR(Exclusive or : 입력값이 모두 같으면 False) 구현 실패\n",
        "  - 이에 단일 퍼셉트론을 여러개 연결해보는 개념이 등장 : Multi Layer Perceptron (다층퍼셉트론)\n",
        "  - (머신러닝에서의 다항화,다중화가 개념이 아닌) 파라미터 개수를 증가시키는 또 다른 방법으로 단순함수를 여러개 사용하는 방법\n",
        "    - 여러개의 함수를 연속되게 연결시킨 '부스팅' 개념과 유사 \n",
        "    - 앞의노드의 아웃풋이 다음노드의 인풋으로 들어감\n",
        "    - GPU가 필요한 이유 : 단순한 연산을 대량으로 해야하니까 (복잡한 연산의 개념이 아님 =CPU)\n",
        "\n",
        "<BR><BR>\n",
        "  \n",
        " <b> MLP </b>\n",
        "   - MLP는 input layer →  hidden layer (함수형태) →  output layer (함수형태) 로 구성\n",
        "   - MLP는 hidden layer 한개, 레이어에 연결된 선은 모두 파라미터이며, <br> hidden layer가 두개 이상인 것을 Deep Neural Network(DNN)이라고 하고, 파라미터의 개수가 극도로 많아진다. ~ tensorflow로 만들어야함\n",
        "  - 파라미터 개수 : ∑((Input_X 개수 * w 노드수) + bias 개수)\n",
        "  \n",
        "<br><br>\n",
        "참고 \n",
        "\n",
        " - 스칼라는 소문자, 벡터는 대문자\n",
        " - 행렬곱\n",
        "  - 앞열뒤행 앞행뒤열 개수가 같아야함\n",
        "  - 앞행뒤열 = 결과물 차원\n",
        " - [tensorflow 참고사이트](https://playground.tensorflow.org)\n",
        "   - 머신러닝 방식은 다항회귀식 또는 X1X2(곱하기) 상호작용효과  등  통계기법을 사용하는 방식\n",
        "   - 딥러닝은 다중회귀를 여러개 사용하는 방식\n",
        " - MLP 파라미터 \n",
        "   - epoch : 학습횟수\n",
        " - loss가 떨어져야 학습효과가 있는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aLTiwMEU6dN"
      },
      "source": [
        "# I. 수치미분(Numerical Derivative)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jtNqiYxVccXs"
      },
      "source": [
        "<B>미분</B>  <br>\n",
        "x 위치에서의 접선의 기울기 → <b> '순간 변화량' </b> <br>\n",
        "\n",
        "\n",
        "<br><br>\n",
        "<b>수치미분</b>\n",
        "<br>\n",
        "\n",
        "하나의 함수를 사용할 경우에는, 미분대상이 확실하게 정해져 있어 편미분 사용이 가능하지만, <br>\n",
        "MLP는 함수가 여러개고 함수가 연결되는 시점마다 예측값이 바뀌게 되어<br>\n",
        "오차함수가 고정 되어있지 않고, 포워드의 흐름에 따라 변화하기 때문에 <br> 편미분 방정식 사용(해석미분)이 불가능하고 <br> \n",
        "아주 작은 delta 값을 차분에 직접 넣어주는 수치미분이 필요하다. (즉, 함수를 알 수 없을 때 수치미분 수행) <br>\n",
        "수치 미분의 방법 : x 위치에서의  접선의 기울기를 구할 때\n",
        "  - 단방향 : 한지점에서 좁혀옴 <br>\n",
        "     ``` 미분식 : f(x+d) - f(x) / d ```\n",
        "  - 양방향 : 양측 두지점으로부터 좁혀옴 →  통상 한점을 기준으로 회귀선을 긋는것보다, <br> \n",
        "     과거 데이터의 방향성도 반영할수 있는 두지점 을 지나는 회귀선이 더 예측력이 좋기 때문에, 양측에서 구함 <br>\n",
        "     - '+' delta, '−' delta (양방향)\n",
        "     - delta를 0으로 보냄 (+,-delta와의 접점이 x로 변경됨)\n",
        "     - f(x+d) - f(x-d) / 2d \n",
        "     - x가 하나인게 아니라, 여러개의 w도 있고 b도 있음 다 바뀌어야함\n",
        "\n",
        "     ```미분식 : f(x+d) - f(x-d) / 2d```\n",
        "\n",
        "  - 두 방식의 결과값은 같음\n",
        "<br>\n",
        "\n",
        "\n",
        "<b>편미분 (해석미분)</b>\n",
        "<br>\n",
        " - 입력변수가 두개이상인 다변수함수의 미분을 수행하는 것\n",
        " - 변수한개를 제외한 나머지 변수들을 상수로 취급\n",
        " - w,b 각 관점에서의 에러의 변화량 \n",
        " - df(x,y) / d(x) : x가 변할때 함수의 변화 <BR>\n",
        " \n",
        "    ```f(x,y)= 3x + 2xy + y²``` <BR>\n",
        "    ```f(x,y) / d(x) = 3+2y``` <BR>\n",
        "    ```f(x,y) / d(y) = 2x+2y``` <BR>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbPgODpVzdHI"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UugARcKaldr"
      },
      "source": [
        "> ## 1) Import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0NUWP2IRnZj"
      },
      "outputs": [],
      "source": [
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWi7oYzwavvl"
      },
      "source": [
        "> ## 2) gradient( ) 함수 정의\n",
        "\n",
        "* 다변수 함수의 수치미분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y19zci4Rsca"
      },
      "outputs": [],
      "source": [
        "def gradient(machine, param): #machine: 오차함수, param : w,b(1)\n",
        "\n",
        "    #b처리\n",
        "    if param.ndim == 1:\n",
        "        temp_param = param\n",
        "        delta = 0.00005 #delta 값 지정\n",
        "        learned_param = np.zeros(param.shape)\n",
        "        \n",
        "        #학습\n",
        "        for index in range(len(param)):\n",
        "            target_param = float(temp_param[index])    # 초기 랜덤 추출된 파라미터값으로 x setting\n",
        "            temp_param[index] = target_param + delta    # x + delta 이동           \n",
        "            param_plus_delta = machine(temp_param)      # x + delta 에서의 CEE값\n",
        "            temp_param[index] = target_param - delta    # x - delta 이동\n",
        "            param_minus_delta = machine(temp_param)     # x - delta 에서의 CEE값\n",
        "            learned_param[index] = (param_plus_delta - param_minus_delta ) / (2 * delta) #기울기구하기 -> 학습 (파라미터 업데이트)\n",
        "            temp_param[index] = target_param   \n",
        "\n",
        "        return learned_param #기울기 반환\n",
        "        \n",
        "   #w처리\n",
        "    elif param.ndim == 2:\n",
        "        temp_param = param\n",
        "        delta = 0.00005\n",
        "        learned_param = np.zeros(param.shape)\n",
        "    \n",
        "        rows = param.shape[0]\n",
        "        columns = param.shape[1]\n",
        "\n",
        "        #학습\n",
        "        for row in range(rows):\n",
        "            for column in range(columns):\n",
        "                target_param = float(temp_param[row, column])\n",
        "                temp_param[row, column] = target_param + delta            \n",
        "                param_plus_delta = machine(temp_param)\n",
        "                temp_param[row, column] = target_param - delta            \n",
        "                param_minus_delta = machine(temp_param)\n",
        "                learned_param[row, column] = (param_plus_delta - param_minus_delta) / (2 * delta)\n",
        "                temp_param[row, column] = target_param\n",
        "\n",
        "        return learned_param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kyyj7OuVR96"
      },
      "source": [
        "# II. Logic Gate( ) - 'AND', 'OR', 'NAND'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-nfRPT_bZLY"
      },
      "source": [
        "> ## 1) sigmoid( ) 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3pPJzd9Vmgg"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "def sigmoid(x):\n",
        "    y_hat = 1 / (1 + np.exp(-x))\n",
        "    return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7rTKDZKbfhb"
      },
      "source": [
        "> ## 2) LogicGate 클래스 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcH3S-1xWUWi"
      },
      "outputs": [],
      "source": [
        "class LogicGate:\n",
        "    \n",
        "    def __init__(self, gate_Type, X_input, y_output):  \n",
        "\n",
        "# gate_Type 문자열 지정 Member      \n",
        "        self.Type = gate_Type\n",
        "        \n",
        "# X_input, y_output Member 초기화\n",
        "        self.X_input = X_input.reshape(4, 2)\n",
        "        self.y_output = y_output.reshape(4, 1)\n",
        "        \n",
        "# W, b Member 초기화\n",
        "        self.W = np.random.rand(2, 1)  # w 2개\n",
        "        self.b = np.random.rand(1)\n",
        "                        \n",
        "# learning_rate Member 지정\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "# Cost_Function(CEE) Method\n",
        "    def cost_func(self):\n",
        "        z = np.dot(self.X_input, self.W) + self.b #내적값으로 y hat 구함\n",
        "        y_hat = sigmoid(z)\n",
        "        \n",
        "        return -np.sum(self.y_output * np.log(y_hat) + (1 - self.y_output) * np.log(1 - y_hat)) #CEE에러 구함     \n",
        "\n",
        "# Learning Method \n",
        "    def fit(self):\n",
        "        machine = lambda x : self.cost_func()\n",
        "        print('Initial Cost = ', self.cost_func())\n",
        "        \n",
        "        for step in  range(10001): #10000번 학습, 3개의 파라미터\n",
        "            self.W = self.W - self.learning_rate * gradient(machine, self.W) #미분값 빼주기\n",
        "            self.b = self.b - self.learning_rate * gradient(machine, self.b)\n",
        "    \n",
        "            if (step % 1000 == 0):\n",
        "                print('Step = ', step, 'Cost = ', self.cost_func())\n",
        "                \n",
        "# Predict Method\n",
        "    def predict(self, input_data):\n",
        "        \n",
        "        z = np.dot(input_data, self.W) + self.b\n",
        "        y_prob = sigmoid(z)\n",
        "    \n",
        "        if y_prob > 0.5:\n",
        "            result = 1\n",
        "        else:\n",
        "            result = 0\n",
        "    \n",
        "        return y_prob, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zdafbjmd0t2"
      },
      "source": [
        "> ## 3) AND_Gate\n",
        "\n",
        "* X_input, y_output 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGAxT7UXVEP"
      },
      "outputs": [],
      "source": [
        "X_input  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_output = np.array([0, 0, 0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG2U0plZlR_L"
      },
      "source": [
        "* AND_Gate 객체 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pJp_noreWmV",
        "outputId": "a634f0ff-6a8b-44ad-f6b2-4c33be62cc37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cost =  2.878875033450503\n",
            "Step =  0 Cost =  2.8595257759083834\n",
            "Step =  1000 Cost =  1.0027837941122864\n",
            "Step =  2000 Cost =  0.65845850060898\n",
            "Step =  3000 Cost =  0.4904019306660388\n",
            "Step =  4000 Cost =  0.38962648274757283\n",
            "Step =  5000 Cost =  0.32245852127920616\n",
            "Step =  6000 Cost =  0.27457645649320683\n",
            "Step =  7000 Cost =  0.23878316685852713\n",
            "Step =  8000 Cost =  0.2110565268435128\n",
            "Step =  9000 Cost =  0.18897285039903294\n",
            "Step =  10000 Cost =  0.17098595237105912\n"
          ]
        }
      ],
      "source": [
        "AND_Gate = LogicGate('AND_GATE', X_input, y_output)\n",
        "\n",
        "AND_Gate.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEAcasYalbLy"
      },
      "source": [
        "* AND_Gate 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj9Rueh2ezxd",
        "outputId": "5f0c655e-11d5-4852-d665-b88ac535542e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AND_GATE \n",
            "\n",
            "[0 0]  =  0\n",
            "[0 1]  =  0\n",
            "[1 0]  =  0\n",
            "[1 1]  =  1\n"
          ]
        }
      ],
      "source": [
        "print(AND_Gate.Type, '\\n')\n",
        "\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "    (sigmoid_val, logical_val) = AND_Gate.predict(input_data) \n",
        "    print(input_data, ' = ', logical_val)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCwDjzmWfOMH"
      },
      "source": [
        "> ## 4) OR_Gate\n",
        "\n",
        "* X_input, y_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWzMgGHUfcPZ"
      },
      "outputs": [],
      "source": [
        "X_input  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_output = np.array([0, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZGv2PQlqTb"
      },
      "source": [
        "* OR_Gate 객체 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHMZWyWffwzJ",
        "outputId": "a70e0469-63e3-4113-efee-b95dbb479f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cost =  2.007690456839189\n",
            "Step =  0 Cost =  2.0001663783870156\n",
            "Step =  1000 Cost =  0.7195127181915231\n",
            "Step =  2000 Cost =  0.43171261169417574\n",
            "Step =  3000 Cost =  0.303734665397433\n",
            "Step =  4000 Cost =  0.2326307583702944\n",
            "Step =  5000 Cost =  0.1878015165007793\n",
            "Step =  6000 Cost =  0.15711803044652423\n",
            "Step =  7000 Cost =  0.13486976501087267\n",
            "Step =  8000 Cost =  0.11803436894538714\n",
            "Step =  9000 Cost =  0.10486979037578495\n",
            "Step =  10000 Cost =  0.09430437043763612\n"
          ]
        }
      ],
      "source": [
        "OR_Gate = LogicGate('OR_GATE', X_input, y_output)\n",
        "\n",
        "OR_Gate.fit() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsokT4WFl3Xa"
      },
      "source": [
        "* OR_Gate 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCGWz7REfyHo",
        "outputId": "4bd19ba3-d742-4f7a-a895-a566d873f9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OR_GATE \n",
            "\n",
            "[0 0]  =  0\n",
            "[0 1]  =  1\n",
            "[1 0]  =  1\n",
            "[1 1]  =  1\n"
          ]
        }
      ],
      "source": [
        "print(OR_Gate.Type, '\\n')\n",
        "\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "    (sigmoid_val, logical_val) = OR_Gate.predict(input_data) \n",
        "    print(input_data, ' = ', logical_val)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp8KycaqfTk_"
      },
      "source": [
        "> ## 5) NAND_Gate\n",
        "\n",
        "* X_input, y_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_4wxCkrfdBh"
      },
      "outputs": [],
      "source": [
        "X_input  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_output = np.array([1, 1, 1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcWUPdI4ltaJ"
      },
      "source": [
        "* NAND_Gate 객체 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLrdFDHzglGo",
        "outputId": "a41e498f-2e7d-49e7-d845-2ae18cb8300c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cost =  2.4605376527908236\n",
            "Step =  0 Cost =  2.456126715758164\n",
            "Step =  1000 Cost =  1.0134152863612131\n",
            "Step =  2000 Cost =  0.6629533904018967\n",
            "Step =  3000 Cost =  0.4929191070321558\n",
            "Step =  4000 Cost =  0.3912367295359107\n",
            "Step =  5000 Cost =  0.3235747270796513\n",
            "Step =  6000 Cost =  0.27539388395097825\n",
            "Step =  7000 Cost =  0.23940644317196375\n",
            "Step =  8000 Cost =  0.21154675459610867\n",
            "Step =  9000 Cost =  0.1893680678132345\n",
            "Step =  10000 Cost =  0.17131104679880255\n"
          ]
        }
      ],
      "source": [
        "NAND_Gate = LogicGate('NAND_GATE', X_input, y_output)\n",
        "\n",
        "NAND_Gate.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX3f5qfBl62B"
      },
      "source": [
        "* NAND_Gate 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O18S4Ox-gs8X",
        "outputId": "7f55a60c-dcc2-4fde-b756-5d5dc60c1a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAND_GATE \n",
            "\n",
            "[0 0]  =  1\n",
            "[0 1]  =  1\n",
            "[1 0]  =  1\n",
            "[1 1]  =  0\n"
          ]
        }
      ],
      "source": [
        "print(NAND_Gate.Type, '\\n')\n",
        "\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "    (sigmoid_val, logical_val) = NAND_Gate.predict(input_data) \n",
        "    print(input_data, ' = ', logical_val)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfzunHXAfWyl"
      },
      "source": [
        "# III. XOR_Gate Issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFmJld2kY8I"
      },
      "source": [
        "> ## 1) XOR_Gate Failure\n",
        "\n",
        "* X_input, y_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHbjtJh6fduB"
      },
      "outputs": [],
      "source": [
        "X_input  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_output = np.array([0, 1, 1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwH1C0AUlv5P"
      },
      "source": [
        "* XOR_Gate 객체 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FF1q21ahATG",
        "outputId": "b5a0f326-2153-412d-b6bf-f93b5c7f2125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cost =  3.759170406915646\n",
            "Step =  0 Cost =  3.7366934301791694\n",
            "Step =  1000 Cost =  2.7730112128684783\n",
            "Step =  2000 Cost =  2.77259301982848\n",
            "Step =  3000 Cost =  2.7725888138001515\n",
            "Step =  4000 Cost =  2.772588725537796\n",
            "Step =  5000 Cost =  2.7725887223766845\n",
            "Step =  6000 Cost =  2.772588722245608\n",
            "Step =  7000 Cost =  2.7725887222400303\n",
            "Step =  8000 Cost =  2.772588722239792\n",
            "Step =  9000 Cost =  2.7725887222397816\n",
            "Step =  10000 Cost =  2.772588722239781\n"
          ]
        }
      ],
      "source": [
        "XOR_Gate = LogicGate('XOR_GATE', X_input, y_output)\n",
        "\n",
        "XOR_Gate.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2hDj20rl9NR"
      },
      "source": [
        "* XOR_Gate 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn5Su92GhQY-",
        "outputId": "c8f1bcd5-a5bc-4f73-e7db-31f7795ec983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XOR_GATE \n",
            "\n",
            "[0 0]  =  1\n",
            "[0 1]  =  1\n",
            "[1 0]  =  1\n",
            "[1 1]  =  0\n"
          ]
        }
      ],
      "source": [
        "print(XOR_Gate.Type, '\\n')\n",
        "\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "    (sigmoid_val, logical_val) = XOR_Gate.predict(input_data) \n",
        "    print(input_data, ' = ', logical_val)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT2piTfAiMze"
      },
      "source": [
        "> ## 2) XOR_Gate Succeed\n",
        "\n",
        "* XOR를 (NAND + OR) 계층 및 AND 계층의 조합으로 연산\n",
        "* 이전 학습된 Parametrer로 XOR 수행\n",
        "* single layer의 단순조합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o93-rsvliQrT"
      },
      "outputs": [],
      "source": [
        "input_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "HL1_1 = []    # NAND 출력\n",
        "HL1_2 = []    # OR   출력\n",
        "\n",
        "new_input_data = []  # AND      입력\n",
        "final_output = []    # AND(XOR) 출력\n",
        "\n",
        "for index in range(len(input_data)):\n",
        "\n",
        "    HL1_1 = NAND_Gate.predict(input_data[index])  # NAND 출력\n",
        "    HL1_2 = OR_Gate.predict(input_data[index])    # OR   출력\n",
        "    \n",
        "    new_input_data.append(HL1_1[-1])    # AND 입력\n",
        "    new_input_data.append(HL1_2[-1])    # AND 입력\n",
        "    \n",
        "    (sigmoid_val, logical_val) = AND_Gate.predict(np.array(new_input_data))\n",
        "    \n",
        "    final_output.append(logical_val)    # AND(XOR) 출력    \n",
        "    new_input_data = []                 # AND 입력 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8wZ7HS4mhsx",
        "outputId": "087196e5-f511-4b4c-e640-d90145012b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XOR_GATE \n",
            "\n",
            "[0 0]  =  0\n",
            "[0 1]  =  1\n",
            "[1 0]  =  1\n",
            "[1 1]  =  0\n"
          ]
        }
      ],
      "source": [
        "print(XOR_Gate.Type, '\\n')\n",
        "\n",
        "for index in range(len(input_data)):    \n",
        "    print(input_data[index], ' = ', final_output[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBXcodpdp98R"
      },
      "source": [
        "> ## 3) XOR_Gate Learning\n",
        " - multi layer 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpzSonjcxVTM"
      },
      "source": [
        "### (1) XOR_Gate Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU2ZjRtQp9Xr"
      },
      "outputs": [],
      "source": [
        "class XOR_Gate:\n",
        "    \n",
        "    def __init__(self, gate_Type, X_input, y_output):  \n",
        "\n",
        "# gate_Type 문자열 지정 Member      \n",
        "        self.Type = gate_Type\n",
        "        \n",
        "# X_input, y_output Member 초기화\n",
        "        self.X_input = X_input.reshape(4, 2)\n",
        "        self.y_output = y_output.reshape(4, 1)\n",
        "        \n",
        "# W_1, b_1 Member 초기화\n",
        "        self.W_1 = np.random.rand(2, 2)  \n",
        "        self.b_1 = np.random.rand(2)\n",
        "\n",
        "# W_2, b_2 Member 초기화\n",
        "        self.W_2 = np.random.rand(2, 1)  \n",
        "        self.b_2 = np.random.rand(1)\n",
        "\n",
        "# learning_rate Member 지정\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "# Cost_Function(CEE) Method\n",
        "    def cost_func(self):\n",
        "\n",
        "        z_1 = np.dot(self.X_input, self.W_1) + self.b_1     # Hidden Layer\n",
        "        a_1 = sigmoid(z_1)                                \n",
        "        \n",
        "        z_2 = np.dot(a_1, self.W_2) + self.b_2              # Output Layer\n",
        "        y_hat = sigmoid(z_2)                        \n",
        "\n",
        "        return -np.sum(self.y_output * np.log(y_hat) + (1 - self.y_output) * np.log(1 - y_hat))      \n",
        "\n",
        "# Learning Method\n",
        "    def fit(self):\n",
        "        machine = lambda x : self.cost_func()\n",
        "        print('Initial Cost = ', self.cost_func())\n",
        "        \n",
        "        for step in  range(50001): #9개의 파라미터를 학습\n",
        "            self.W_1 = self.W_1- self.learning_rate * gradient(machine, self.W_1)\n",
        "            self.b_1 = self.b_1 - self.learning_rate * gradient(machine, self.b_1)\n",
        "\n",
        "            self.W_2 = self.W_2 - self.learning_rate * gradient(machine, self.W_2)\n",
        "            self.b_2 = self.b_2 - self.learning_rate * gradient(machine, self.b_2)\n",
        "    \n",
        "            if (step % 1000 == 0):\n",
        "                print('Step = ', step, 'Cost = ', self.cost_func())\n",
        "                \n",
        "# Predict Method\n",
        "    def predict(self, input_data):\n",
        "        \n",
        "        z_1 = np.dot(input_data, self.W_1) + self.b_1     # Hidden Layer\n",
        "        a_1 = sigmoid(z_1)                                \n",
        "        \n",
        "        z_2 = np.dot(a_1, self.W_2) + self.b_2            # Output Layer\n",
        "        y_prob = sigmoid(z_2)                             \n",
        "\n",
        "\n",
        "        if y_prob > 0.5:\n",
        "            result = 1\n",
        "        else:\n",
        "            result = 0\n",
        "    \n",
        "        return y_prob, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kzJAz8Sv5hQ"
      },
      "source": [
        "### (2) X_input, y_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Y-0WxQv5hS"
      },
      "outputs": [],
      "source": [
        "X_input  = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_output = np.array([0, 1, 1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJVNolWrv5hS"
      },
      "source": [
        "### (3) XOR_Gate_2.learn( )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nfufi7Cv5hT",
        "outputId": "6f02d8f9-f88e-4133-92a9-e1bba18a7c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cost =  3.8082754286217275\n",
            "Step =  0 Cost =  3.776649466727436\n",
            "Step =  1000 Cost =  2.770764820139756\n",
            "Step =  2000 Cost =  2.769538155061292\n",
            "Step =  3000 Cost =  2.767725095432642\n",
            "Step =  4000 Cost =  2.7647157078625564\n",
            "Step =  5000 Cost =  2.759285088123649\n",
            "Step =  6000 Cost =  2.7488807939464177\n",
            "Step =  7000 Cost =  2.728393613889321\n",
            "Step =  8000 Cost =  2.6884741805540178\n",
            "Step =  9000 Cost =  2.613636532430996\n",
            "Step =  10000 Cost =  2.489350610532968\n",
            "Step =  11000 Cost =  2.3335758397803557\n",
            "Step =  12000 Cost =  2.1834945276089974\n",
            "Step =  13000 Cost =  2.0301162621862994\n",
            "Step =  14000 Cost =  1.8026256177172368\n",
            "Step =  15000 Cost =  1.3902116440728358\n",
            "Step =  16000 Cost =  0.9014465815623369\n",
            "Step =  17000 Cost =  0.5770419799726589\n",
            "Step =  18000 Cost =  0.4002100902062164\n",
            "Step =  19000 Cost =  0.2993735263988663\n",
            "Step =  20000 Cost =  0.23663973192584264\n",
            "Step =  21000 Cost =  0.19456453855903877\n",
            "Step =  22000 Cost =  0.16464987497186123\n",
            "Step =  23000 Cost =  0.1424034444534819\n",
            "Step =  24000 Cost =  0.12526765523977204\n",
            "Step =  25000 Cost =  0.11169307655964973\n",
            "Step =  26000 Cost =  0.1006916497026919\n",
            "Step =  27000 Cost =  0.09160594349568295\n",
            "Step =  28000 Cost =  0.08398268259293605\n",
            "Step =  29000 Cost =  0.07749980556623332\n",
            "Step =  30000 Cost =  0.07192251894648655\n",
            "Step =  31000 Cost =  0.06707580582794778\n",
            "Step =  32000 Cost =  0.0628266573604386\n",
            "Step =  33000 Cost =  0.05907225599448973\n",
            "Step =  34000 Cost =  0.05573191691995178\n",
            "Step =  35000 Cost =  0.05274146867035092\n",
            "Step =  36000 Cost =  0.05004925598031547\n",
            "Step =  37000 Cost =  0.04761324544239549\n",
            "Step =  38000 Cost =  0.04539889574548642\n",
            "Step =  39000 Cost =  0.04337756752491185\n",
            "Step =  40000 Cost =  0.04152532025774633\n",
            "Step =  41000 Cost =  0.03982199089755074\n",
            "Step =  42000 Cost =  0.038250480383099014\n",
            "Step =  43000 Cost =  0.036796195437550944\n",
            "Step =  44000 Cost =  0.03544660771125482\n",
            "Step =  45000 Cost =  0.03419090253844127\n",
            "Step =  46000 Cost =  0.03301969680596043\n",
            "Step =  47000 Cost =  0.0319248106123247\n",
            "Step =  48000 Cost =  0.0308990811497581\n",
            "Step =  49000 Cost =  0.0299362099946788\n",
            "Step =  50000 Cost =  0.0290306370298809\n"
          ]
        }
      ],
      "source": [
        "XOR_Gate_2 = XOR_Gate('XOR_GATE', X_input, y_output)\n",
        "\n",
        "XOR_Gate_2.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkHSTVJVwX--"
      },
      "source": [
        "### (4) XOR_Gate_2.predict( )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9cbHccRwX--",
        "outputId": "04a0ce17-0439-4070-c2cb-33ea1d85cd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XOR_GATE \n",
            "\n",
            "[0 0]  =  0\n",
            "[0 1]  =  1\n",
            "[1 0]  =  1\n",
            "[1 1]  =  0\n"
          ]
        }
      ],
      "source": [
        "print(XOR_Gate_2.Type, '\\n')\n",
        "\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "\n",
        "for input_data in test_data:\n",
        "    (sigmoid_val, logical_val) = XOR_Gate_2.predict(input_data) \n",
        "    print(input_data, ' = ', logical_val)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiAhFISVnkkm"
      },
      "source": [
        "# \n",
        "# \n",
        "# \n",
        "# THE END\n",
        "# \n",
        "# \n",
        "# "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c4a217330dafb44a177311bf304eb7602117568170dedb9db52856e3c583233"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
